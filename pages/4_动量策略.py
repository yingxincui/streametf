import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import akshare as ak
from datetime import datetime, timedelta
import os
import json

# åŠ¨é‡ç­–ç•¥é¡µé¢

# é»˜è®¤ETFæ± 
DEFAULT_ETF_POOL = {
    '510300': '300ETF',
    '159915': 'åˆ›ä¸šæ¿',
    '513050': 'ä¸­æ¦‚äº’è”ç½‘ETF',
    '159941': 'çº³æŒ‡ETF',
    '518880': 'é»„é‡‘ETF',
    '511090':'30å¹´å›½å€º'
}

# ç¼“å­˜ç›®å½•
CACHE_DIR = "etf_cache"
if not os.path.exists(CACHE_DIR):
    os.makedirs(CACHE_DIR)

def get_cache_file_path(symbol):
    """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
    return os.path.join(CACHE_DIR, f"{symbol}_data.csv")

def get_cache_meta_file_path():
    """è·å–ç¼“å­˜å…ƒæ•°æ®æ–‡ä»¶è·¯å¾„"""
    return os.path.join(CACHE_DIR, "cache_meta.json")

def load_cache_meta():
    """åŠ è½½ç¼“å­˜å…ƒæ•°æ®"""
    meta_file = get_cache_meta_file_path()
    if os.path.exists(meta_file):
        try:
            with open(meta_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return {}
    return {}

def save_cache_meta(meta_data):
    """ä¿å­˜ç¼“å­˜å…ƒæ•°æ®"""
    meta_file = get_cache_meta_file_path()
    try:
        with open(meta_file, 'w', encoding='utf-8') as f:
            json.dump(meta_data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        small_log(f"ä¿å­˜ç¼“å­˜å…ƒæ•°æ®å¤±è´¥: {e}")

def is_cache_valid(symbol):
    """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆï¼ˆåŒä¸€å¤©çš„æ•°æ®ï¼‰"""
    today = datetime.now().strftime('%Y-%m-%d')
    meta_data = load_cache_meta()
    
    # ç¡®ä¿symbolä¸ºå­—ç¬¦ä¸²ç±»å‹
    symbol_str = str(symbol)
    if symbol_str in meta_data:
        last_update = meta_data[symbol_str].get('last_update', '')
        return last_update == today
    return False

def save_to_cache(symbol, df):
    """ä¿å­˜æ•°æ®åˆ°ç¼“å­˜"""
    try:
        cache_file = get_cache_file_path(symbol)
        df.to_csv(cache_file, encoding='utf-8')
        
        # æ›´æ–°å…ƒæ•°æ®
        meta_data = load_cache_meta()
        # ç¡®ä¿symbolä¸ºå­—ç¬¦ä¸²ç±»å‹
        symbol_str = str(symbol)
        meta_data[symbol_str] = {
            'last_update': datetime.now().strftime('%Y-%m-%d'),
            'data_length': len(df),
            'latest_date': df.index[-1].strftime('%Y-%m-%d') if len(df) > 0 else ''
        }
        save_cache_meta(meta_data)
        
    except Exception as e:
        small_log(f"ä¿å­˜{symbol}ç¼“å­˜å¤±è´¥: {e}")

def load_from_cache(symbol):
    """ä»ç¼“å­˜åŠ è½½æ•°æ®"""
    try:
        cache_file = get_cache_file_path(symbol)
        if os.path.exists(cache_file):
            # ç¡®ä¿æ—¥æœŸç´¢å¼•æ­£ç¡®è§£æ
            df = pd.read_csv(cache_file, index_col=0)
            df.index = pd.to_datetime(df.index)
            return df
    except Exception as e:
        small_log(f"åŠ è½½{symbol}ç¼“å­˜å¤±è´¥: {e}")
    return None

# è·å–ETFæ•°æ®çš„å‡½æ•°
def fetch_etf_data(symbol="510300"):
    # æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ
    if is_cache_valid(symbol):
        cached_data = load_from_cache(symbol)
        if cached_data is not None:
            small_log(f"ä½¿ç”¨{symbol}ç¼“å­˜æ•°æ®")
            return cached_data
    
    # ç¼“å­˜æ— æ•ˆæˆ–ä¸å­˜åœ¨ï¼Œä»APIè·å–æ•°æ®
    small_log(f"ä»APIè·å–{symbol}æ•°æ®...")
    try:
        # ä½¿ç”¨ akshare çš„ fund_etf_hist_em æ¥å£è·å– ETF æ•°æ®
        df = ak.fund_etf_hist_em(symbol=symbol, period="daily", adjust='qfq')
        # è½¬æ¢æ—¥æœŸæ ¼å¼
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])  # å‡è®¾æ—¥æœŸåˆ—åä¸º 'æ—¥æœŸ'
        df.set_index('æ—¥æœŸ', inplace=True)
        # é‡å‘½ååˆ—ä»¥ç¬¦åˆæ ‡å‡†æ ¼å¼
        df.rename(columns={
            'å¼€ç›˜': 'Open',
            'æœ€é«˜': 'High',
            'æœ€ä½': 'Low',
            'æ”¶ç›˜': 'Close',
            'æˆäº¤é‡': 'Volume'
        }, inplace=True)
        
        # ç¡®ä¿ç´¢å¼•æ˜¯datetimeç±»å‹
        df.index = pd.to_datetime(df.index)
        
        # ä¿å­˜åˆ°ç¼“å­˜
        save_to_cache(symbol, df)
        return df
        
    except Exception as e:
        small_log(f"è·å–{symbol}æ•°æ®å¤±è´¥: {e}")
        # å°è¯•ä½¿ç”¨ç¼“å­˜æ•°æ®ï¼ˆå³ä½¿ä¸æ˜¯ä»Šå¤©çš„ï¼‰
        cached_data = load_from_cache(symbol)
        if cached_data is not None:
            small_log(f"ä½¿ç”¨{symbol}å†å²ç¼“å­˜æ•°æ®")
            return cached_data
        return pd.DataFrame()

# è®¡ç®—åŠ¨é‡å’Œå‡çº¿
def calculate_momentum_and_ma(df, momentum_period=20, ma_period=28):
    # è®¡ç®—åŠ¨é‡ï¼šå½“å‰æ”¶ç›˜ä»·ä¸20å¤©å‰æ”¶ç›˜ä»·çš„ç™¾åˆ†æ¯”å˜åŒ–
    df['Momentum'] = df['Close'] / df['Close'].shift(momentum_period) - 1
    # è®¡ç®—28å¤©å‡çº¿
    df['MA'] = df['Close'].rolling(window=ma_period).mean()
    return df

# ç­›é€‰ç¬¦åˆæ¡ä»¶çš„ETF
def select_etfs(etf_list, etf_names, momentum_period=20, ma_period=28):
    etf_data = {}
    for symbol in etf_list:
        try:
            df = fetch_etf_data(symbol)
            if df.empty:
                small_log(f"{symbol} æ•°æ®ä¸ºç©ºï¼Œå·²è·³è¿‡")
                continue
            df = calculate_momentum_and_ma(df, momentum_period, ma_period)
            etf_data[symbol] = df
        except Exception as e:
            small_log(f"å¤„ç†{symbol}æ•°æ®å¤±è´¥: {e}")
            continue
    
    if not etf_data:
        small_log("æ— æ³•è·å–ä»»ä½•ETFæ•°æ®")
        return [], []
    
    # è·å–æœ€æ–°çš„æ•°æ®
    latest_data = {symbol: df.iloc[-1] for symbol, df in etf_data.items()}
    
    # æ”¶é›†æ‰€æœ‰ETFçš„åŠ¨é‡å’Œæ˜¯å¦å¤§äºå‡çº¿çš„ä¿¡æ¯
    all_etfs = []
    for symbol, data in latest_data.items():
        above_ma = data['Close'] > data['MA']
        all_etfs.append((symbol, etf_names[symbol], data['Close'], data['MA'], data['Momentum'], above_ma))
    
    # æŒ‰åŠ¨é‡æ’åº
    all_etfs.sort(key=lambda x: x[4], reverse=True)
    
    # é€‰æ‹©åŠ¨é‡æ’åå‰ä¸¤ä½ä¸”æ”¶ç›˜ä»·å¤§äºå‡çº¿çš„ETF
    selected_etfs = [(etf[0], etf[1], etf[2], etf[3], etf[4]) for etf in all_etfs if etf[5]][:2]
    return selected_etfs, all_etfs

# å›æµ‹å‡½æ•°
def backtest_strategy(etf_list, etf_names, start_date, end_date, momentum_period=20, ma_period=28, max_positions=2):
    """å›æµ‹åŠ¨é‡ç­–ç•¥"""
    # è½¬æ¢æ—¥æœŸç±»å‹
    start_date = pd.to_datetime(start_date)
    end_date = pd.to_datetime(end_date)
    
    # è·å–æ‰€æœ‰ETFçš„å†å²æ•°æ®
    etf_data = {}
    for symbol in etf_list:
        try:
            df = fetch_etf_data(symbol)
            if df.empty:
                continue
            # ç­›é€‰æ—¶é—´èŒƒå›´
            df = df[(df.index >= start_date) & (df.index <= end_date)]
            if len(df) < max(momentum_period, ma_period) + 10:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®
                continue
            df = calculate_momentum_and_ma(df, momentum_period, ma_period)
            etf_data[symbol] = df
        except Exception as e:
            small_log(f"å¤„ç†{symbol}æ•°æ®å¤±è´¥: {e}")
            continue
    
    if len(etf_data) < 2:
        small_log("å¯ç”¨ETFæ•°é‡ä¸è¶³2åªï¼Œæ— æ³•å›æµ‹")
        return None, None, None
    
    # è·å–æ‰€æœ‰ETFçš„å…±åŒæ—¥æœŸ
    common_dates = None
    for symbol, df in etf_data.items():
        if common_dates is None:
            common_dates = set(df.index)
        else:
            common_dates = common_dates.intersection(set(df.index))
    
    if len(common_dates) < 30:
        small_log("å…±åŒäº¤æ˜“æ—¥ä¸è¶³30å¤©ï¼Œæ— æ³•å›æµ‹")
        return None, None, None
    
    common_dates = sorted(list(common_dates))
    
    # å›æµ‹é€»è¾‘
    # åˆå§‹åŒ–æŠ•èµ„ç»„åˆå‡€å€¼ï¼Œä»ç¬¬ä¸€ä¸ªæœ‰æ•ˆäº¤æ˜“æ—¥å¼€å§‹
    start_index = max(momentum_period, ma_period)
    portfolio_values = [1.0]  # åˆå§‹å‡€å€¼1.0
    holdings_history = []  # æŒä»“å†å²
    trade_history = []  # äº¤æ˜“å†å²
    
    current_holdings = set()  # å½“å‰æŒä»“
    
    for i, date in enumerate(common_dates):
        if i < start_index:
            # å‰Nå¤©æ•°æ®ä¸è¶³ï¼Œè·³è¿‡
            continue
        
        # è®¡ç®—å½“æ—¥åŠ¨é‡æ’å
        momentums = {}
        candidates = []
        
        for symbol, df in etf_data.items():
            if date in df.index:
                row = df.loc[date]
                if not pd.isna(row['Close']) and not pd.isna(row['MA']) and not pd.isna(row['Momentum']):
                    if row['Close'] > row['MA']:
                        candidates.append(symbol)
                        momentums[symbol] = row['Momentum']
        
        # æŒ‰åŠ¨é‡æ’åºï¼Œå–å‰Nå
        if candidates:
            sorted_candidates = sorted(candidates, key=lambda x: momentums[x], reverse=True)
            top_candidates = sorted_candidates[:max_positions]
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒä»“
            to_sell = current_holdings - set(top_candidates)
            to_buy = set(top_candidates) - current_holdings
            
            # è®°å½•äº¤æ˜“
            for etf in to_sell:
                trade_history.append({
                    'æ—¥æœŸ': date.strftime('%Y-%m-%d'),
                    'ETFä»£ç ': etf,
                    'ETFåç§°': etf_names[etf],
                    'æ“ä½œ': 'å–å‡º',
                    'ä»·æ ¼': etf_data[etf].loc[date, 'Close']
                })
            
            for etf in to_buy:
                trade_history.append({
                    'æ—¥æœŸ': date.strftime('%Y-%m-%d'),
                    'ETFä»£ç ': etf,
                    'ETFåç§°': etf_names[etf],
                    'æ“ä½œ': 'ä¹°å…¥',
                    'ä»·æ ¼': etf_data[etf].loc[date, 'Close']
                })
            
            # æ›´æ–°æŒä»“
            current_holdings = set(top_candidates)
        else:
            # æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„ETFï¼Œæ¸…ä»“
            for etf in current_holdings:
                trade_history.append({
                    'æ—¥æœŸ': date.strftime('%Y-%m-%d'),
                    'ETFä»£ç ': etf,
                    'ETFåç§°': etf_names[etf],
                    'æ“ä½œ': 'å–å‡º',
                    'ä»·æ ¼': etf_data[etf].loc[date, 'Close']
                })
            current_holdings = set()
        
        # è®°å½•æŒä»“
        holdings_history.append({
            'æ—¥æœŸ': date.strftime('%Y-%m-%d'),
            'æŒä»“ETF': list(current_holdings),
            'æŒä»“æ•°é‡': len(current_holdings)
        })
        
        # è®¡ç®—å½“æ—¥æ”¶ç›Š
        if i > 0 and current_holdings:
            # è®¡ç®—æŒä»“ETFçš„å¹³å‡æ”¶ç›Š
            daily_returns = []
            for etf in current_holdings:
                if i > 0:
                    prev_date = common_dates[i-1]
                    if prev_date in etf_data[etf].index and date in etf_data[etf].index:
                        prev_price = etf_data[etf].loc[prev_date, 'Close']
                        curr_price = etf_data[etf].loc[date, 'Close']
                        if prev_price > 0:
                            daily_return = (curr_price / prev_price - 1)
                            daily_returns.append(daily_return)
            
            if daily_returns:
                # è®¡ç®—å¹³å‡æ”¶ç›Š
                avg_daily_return = sum(daily_returns) / len(daily_returns)
                portfolio_values.append(portfolio_values[-1] * (1 + avg_daily_return))
            else:
                portfolio_values.append(portfolio_values[-1])
        else:
            portfolio_values.append(portfolio_values[-1])
    
    # è®¡ç®—å›æµ‹æŒ‡æ ‡
    if len(portfolio_values) > 1:
        # ç¡®ä¿é¦–æœ«å‡€å€¼ä¸æ—¥æœŸä¸€ä¸€å¯¹åº”
        start_value = portfolio_values[0]
        end_value = portfolio_values[-1]
        total_return = (end_value / start_value - 1) * 100
        # ä½¿ç”¨æ­£ç¡®çš„èµ·å§‹æ—¥æœŸè®¡ç®—å¤©æ•°
        start_date_index = max(momentum_period, ma_period)
        days = (common_dates[-1] - common_dates[start_date_index]).days
        annual_return = calculate_annual_return(start_value, end_value, days)
        max_drawdown = calculate_max_drawdown(portfolio_values)
        sharpe_ratio = calculate_sharpe_ratio(portfolio_values)
    else:
        total_return = 0
        annual_return = 0
        max_drawdown = 0
        sharpe_ratio = 0
    
    return {
        'portfolio_values': portfolio_values,
        'dates': [d.strftime('%Y-%m-%d') for d in common_dates[max(momentum_period, ma_period):]],
        'total_return': total_return,  # æ€»æ”¶ç›Šç‡=é¦–æœ«å‡€å€¼ä¹‹æ¯”-1
        'annual_return': annual_return,
        'max_drawdown': max_drawdown,
        'sharpe_ratio': sharpe_ratio,
        'trade_count': len(trade_history)
    }, trade_history, holdings_history

def calculate_annual_return(start_value, end_value, days):
    """è®¡ç®—å¹´åŒ–æ”¶ç›Šç‡"""
    if days <= 0 or start_value <= 0:
        return 0
    years = days / 365.25
    # ä½¿ç”¨æ›´ç¨³å®šçš„å¹´åŒ–æ”¶ç›Šç‡è®¡ç®—æ–¹æ³•
    if years > 0:
        return ((end_value / start_value) ** (1 / years) - 1) * 100
    else:
        return 0

def calculate_max_drawdown(values):
    """è®¡ç®—æœ€å¤§å›æ’¤"""
    if len(values) < 2:
        return 0
    
    max_dd = 0
    peak = values[0]
    
    for value in values:
        if value > peak:
            peak = value
        dd = (peak - value) / peak * 100
        if dd > max_dd:
            max_dd = dd
    
    return max_dd

def calculate_sharpe_ratio(values):
    """è®¡ç®—å¤æ™®æ¯”ç‡"""
    if len(values) < 2:
        return 0
    
    returns = []
    for i in range(1, len(values)):
        if values[i-1] > 0:
            returns.append((values[i] / values[i-1] - 1) * 100)
    
    if not returns:
        return 0
    
    mean_return = np.mean(returns)
    std_return = np.std(returns)
    
    if std_return == 0:
        return 0
    
    # å‡è®¾æ— é£é™©åˆ©ç‡ä¸º3%
    risk_free_rate = 3
    sharpe = (mean_return - risk_free_rate) / std_return * np.sqrt(252)
    
    return sharpe

def small_log(msg):
    st.markdown(f"<div style='font-size:12px; color:#888;'>{msg}</div>", unsafe_allow_html=True)

# ä¿®æ”¹é¡µé¢æ ‡é¢˜
st.title("ğŸ”„ å¤§ç±»èµ„äº§è½®åŠ¨")

st.markdown("""
> æœ¬å·¥å…·åŸºäºåŠ¨é‡ä¸å‡çº¿ç­–ç•¥ï¼Œè‡ªåŠ¨æ¨èå¤§ç±»èµ„äº§ï¼ˆETFï¼‰è½®åŠ¨æŒä»“ã€‚
> 
> - **åŠ¨é‡ç­›é€‰**ï¼šä¼˜å…ˆé€‰æ‹©è¿‘æœŸæ¶¨å¹…é å‰çš„èµ„äº§
> - **å‡çº¿è¿‡æ»¤**ï¼šä»…æŒæœ‰ä»·æ ¼é«˜äºå‡çº¿çš„èµ„äº§
> - **ç­‰æƒåˆ†é…**ï¼šæŒä»“èµ„äº§ç­‰æƒé‡åˆ†é…ï¼Œä¾¿äºå®ç›˜è·Ÿè¸ª
""")
st.markdown("---")

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="å¤§ç±»èµ„äº§è½®åŠ¨",
    page_icon="ğŸ”„",
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ˜¾ç¤ºç¼“å­˜ä¿¡æ¯
st.sidebar.subheader("ç¼“å­˜ä¿¡æ¯")
meta_data = load_cache_meta()
if meta_data:
    st.sidebar.write("**å·²ç¼“å­˜çš„ETFï¼š**")
    for symbol, info in meta_data.items():
        st.sidebar.write(f"- {symbol}: {info.get('last_update', 'N/A')}")
    
    # æ¸…é™¤ç¼“å­˜æŒ‰é’®
    if st.sidebar.button("æ¸…é™¤æ‰€æœ‰ç¼“å­˜"):
        try:
            for file in os.listdir(CACHE_DIR):
                file_path = os.path.join(CACHE_DIR, file)
                if os.path.isfile(file_path):
                    os.remove(file_path)
            st.sidebar.success("ç¼“å­˜å·²æ¸…é™¤")
            st.rerun()
        except Exception as e:
            st.sidebar.error(f"æ¸…é™¤ç¼“å­˜å¤±è´¥: {e}")
else:
    small_log("æš‚æ— ç¼“å­˜æ•°æ®")

# ETFæ± é€‰æ‹©
etf_list = list(DEFAULT_ETF_POOL.keys())
all_etfs = DEFAULT_ETF_POOL

# ä¿®å¤defaultç±»å‹å’Œå†…å®¹
raw_default = list(DEFAULT_ETF_POOL.keys())
if etf_list and raw_default:
    default = [type(etf_list[0])(x) for x in raw_default]
    default = [x for x in default if x in etf_list]
else:
    default = []

st.markdown("**é€‰æ‹©æŒ‡æ•°æ± ï¼ˆå¯å¤šé€‰ï¼Œé»˜è®¤6åªï¼‰ï¼š**")
selected_etfs = st.multiselect(
    "ETFæ± ",
    options=list(all_etfs.keys()),
    default=default,
    format_func=lambda x: f"{x} - {all_etfs.get(x, x)}"
)

# ç­–ç•¥å‚æ•°
col1, col2, col3 = st.columns(3)
with col1:
    momentum_period = st.number_input("åŠ¨é‡å‘¨æœŸ", min_value=5, max_value=60, value=20)
with col2:
    ma_period = st.number_input("å‡çº¿å‘¨æœŸ", min_value=5, max_value=60, value=28)
with col3:
    max_positions = st.number_input("æœ€å¤§æŒä»“æ•°é‡", min_value=1, max_value=5, value=2)

# è‡ªåŠ¨è®¡ç®—é€»è¾‘
def auto_calculate_momentum():
    """è‡ªåŠ¨è®¡ç®—åŠ¨é‡ç­–ç•¥ç»“æœ"""
    if len(selected_etfs) < 2:
        st.warning("è¯·è‡³å°‘é€‰æ‹©2åªETF")
        return None, None
    
    with st.spinner("æ­£åœ¨è·å–ETFæ•°æ®å¹¶è®¡ç®—æŒä»“..."):
        try:
            selected_etfs_result, all_etfs_result = select_etfs(selected_etfs, all_etfs, momentum_period, ma_period)
            return selected_etfs_result, all_etfs_result
        except Exception as e:
            st.error(f"è®¡ç®—å¤±è´¥: {e}")
            import traceback
            st.markdown("<div style='font-size:12px; color:#888;'>" + traceback.format_exc().replace('\n', '<br>') + "</div>", unsafe_allow_html=True)
            return None, None

# æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°è®¡ç®—
current_params = {
    'selected_etfs': selected_etfs,
    'momentum_period': momentum_period,
    'ma_period': ma_period,
    'max_positions': max_positions
}

# å¦‚æœå‚æ•°å‘ç”Ÿå˜åŒ–æˆ–æ²¡æœ‰ç¼“å­˜ç»“æœï¼Œåˆ™é‡æ–°è®¡ç®—
if ('momentum_params' not in st.session_state or 
    st.session_state.momentum_params != current_params or
    'momentum_results' not in st.session_state):
    
    st.session_state.momentum_params = current_params
    selected_etfs_result, all_etfs_result = auto_calculate_momentum()
    st.session_state.momentum_results = {
        'selected_etfs_result': selected_etfs_result,
        'all_etfs_result': all_etfs_result
    }
else:
    # ä½¿ç”¨ç¼“å­˜çš„ç»“æœ
    selected_etfs_result = st.session_state.momentum_results['selected_etfs_result']
    all_etfs_result = st.session_state.momentum_results['all_etfs_result']

# æ˜¾ç¤ºç»“æœ
if selected_etfs_result is not None and all_etfs_result is not None:
    st.markdown("---")
    st.subheader("âœ… æ¨èæŒä»“")
    if selected_etfs_result:
        holdings_data = []
        for symbol, name, close, ma, momentum in selected_etfs_result:
            holdings_data.append({
                'ETFä»£ç ': symbol,
                'ETFåç§°': name,
                'å½“å‰ä»·æ ¼(å…ƒ)': f"{close:.2f}",
                f'{ma_period}æ—¥å‡çº¿': f"{ma:.2f}",
                'ä»·æ ¼-å‡çº¿': f"{close - ma:.2f}",
                f'{momentum_period}æ—¥åŠ¨é‡': f"{momentum*100:.2f}%",
                'æŒä»“æƒé‡': f"{100/len(selected_etfs_result):.1f}%"
            })
        holdings_df = pd.DataFrame(holdings_data)
        st.dataframe(holdings_df.style.background_gradient(cmap="Greens"), use_container_width=True)
        st.success(f"æ¨èæŒæœ‰ {len(selected_etfs_result)} åªETFï¼Œç­‰æƒé‡åˆ†é…")
    else:
        st.warning("æš‚æ— ç¬¦åˆæ¡ä»¶çš„ETFï¼Œå»ºè®®ç©ºä»“")
    
    st.markdown("---")
    st.subheader("ğŸ“Š æ‰€æœ‰ETFåŠ¨é‡æ’å")
    all_etfs_data = []
    for symbol, name, close, ma, momentum, above_ma in all_etfs_result:
        all_etfs_data.append({
            'ETFä»£ç ': symbol,
            'ETFåç§°': name,
            'å½“å‰ä»·æ ¼(å…ƒ)': f"{close:.2f}",
            f'{ma_period}æ—¥å‡çº¿': f"{ma:.2f}",
            'ä»·æ ¼-å‡çº¿': f"{close - ma:.2f}",
            f'{momentum_period}æ—¥åŠ¨é‡': f"{momentum*100:.2f}%",
            'ç«™ä¸Šå‡çº¿': 'âœ…' if above_ma else 'âŒ',
            'æ¨è': 'â­' if (symbol, name, close, ma, momentum) in selected_etfs_result else ''
        })
    all_etfs_df = pd.DataFrame(all_etfs_data)
    all_etfs_df = all_etfs_df.sort_values(f'{momentum_period}æ—¥åŠ¨é‡', ascending=False, key=lambda x: pd.to_numeric(x.str.rstrip('%'), errors='coerce'))
    st.dataframe(all_etfs_df.style.background_gradient(cmap="Blues"), use_container_width=True)
    st.info("åŠ¨é‡æ’åä»…ä¾›å‚è€ƒï¼Œå»ºè®®ç»“åˆè‡ªèº«é£é™©åå¥½å†³ç­–ã€‚")
    
    st.markdown("---")
    st.markdown("""
    **ç­–ç•¥è¯´æ˜ï¼š**
    - ä»…æŒæœ‰ä»·æ ¼é«˜äºå‡çº¿çš„èµ„äº§ï¼Œé¿å…ä¸‹è·Œè¶‹åŠ¿è¸©é›·
    - åŠ¨é‡å‘¨æœŸã€å‡çº¿å‘¨æœŸã€æœ€å¤§æŒä»“æ•°é‡å‡å¯è‡ªå®šä¹‰
    - æ¨èæŒä»“ä¸ºç­‰æƒåˆ†é…ï¼Œä¾¿äºå®ç›˜è·Ÿè¸ª
    - æœ¬å·¥å…·ä¸æ„æˆæŠ•èµ„å»ºè®®ï¼ŒæŠ•èµ„éœ€è°¨æ…
    """)

# æ·»åŠ æ‰‹åŠ¨åˆ·æ–°æŒ‰é’®
if st.button("ğŸ”„ æ‰‹åŠ¨åˆ·æ–°æ•°æ®"):
    # æ¸…é™¤ç¼“å­˜ç»“æœï¼Œå¼ºåˆ¶é‡æ–°è®¡ç®—
    if 'momentum_results' in st.session_state:
        del st.session_state.momentum_results
    if 'momentum_params' in st.session_state:
        del st.session_state.momentum_params
    st.rerun()