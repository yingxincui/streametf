import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import akshare as ak
from datetime import datetime, timedelta
import os
import json

# åŠ¨é‡ç­–ç•¥é¡µé¢

# æ§åˆ¶æ˜¯å¦æ˜¾ç¤ºç¼“å­˜æ—¥å¿—
SHOW_CACHE_LOGS = False

# é»˜è®¤ETFæ± 
DEFAULT_ETF_POOL = {
    '510300': '300ETF',
    '159915': 'åˆ›ä¸šæ¿',
    '513050': 'ä¸­æ¦‚äº’è”ç½‘ETF',
    '159941': 'çº³æŒ‡ETF',
    '518880': 'é»„é‡‘ETF',
    '511090':'30å¹´å›½å€º'
}

# ç¼“å­˜ç›®å½•
CACHE_DIR = "etf_cache"
if not os.path.exists(CACHE_DIR):
    os.makedirs(CACHE_DIR)

def get_cache_file_path(symbol):
    """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
    return os.path.join(CACHE_DIR, f"{symbol}_data.csv")

def get_cache_meta_file_path():
    """è·å–ç¼“å­˜å…ƒæ•°æ®æ–‡ä»¶è·¯å¾„"""
    return os.path.join(CACHE_DIR, "cache_meta.json")

def load_cache_meta():
    """åŠ è½½ç¼“å­˜å…ƒæ•°æ®"""
    meta_file = get_cache_meta_file_path()
    if os.path.exists(meta_file):
        try:
            with open(meta_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return {}
    return {}

def save_cache_meta(meta_data):
    """ä¿å­˜ç¼“å­˜å…ƒæ•°æ®"""
    meta_file = get_cache_meta_file_path()
    try:
        with open(meta_file, 'w', encoding='utf-8') as f:
            json.dump(meta_data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        small_log(f"ä¿å­˜ç¼“å­˜å…ƒæ•°æ®å¤±è´¥: {e}")

def is_cache_valid(symbol):
    """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆï¼ˆåŒä¸€å¤©çš„æ•°æ®ï¼‰"""
    today = datetime.now().strftime('%Y-%m-%d')
    meta_data = load_cache_meta()
    
    # ç¡®ä¿symbolä¸ºå­—ç¬¦ä¸²ç±»å‹
    symbol_str = str(symbol)
    if symbol_str in meta_data:
        last_update = meta_data[symbol_str].get('last_update', '')
        return last_update == today
    return False

def save_to_cache(symbol, df):
    """ä¿å­˜æ•°æ®åˆ°ç¼“å­˜"""
    try:
        cache_file = get_cache_file_path(symbol)
        df.to_csv(cache_file, encoding='utf-8')
        
        # æ›´æ–°å…ƒæ•°æ®
        meta_data = load_cache_meta()
        # ç¡®ä¿symbolä¸ºå­—ç¬¦ä¸²ç±»å‹
        symbol_str = str(symbol)
        meta_data[symbol_str] = {
            'last_update': datetime.now().strftime('%Y-%m-%d'),
            'data_length': len(df),
            'latest_date': df.index[-1].strftime('%Y-%m-%d') if len(df) > 0 else ''
        }
        save_cache_meta(meta_data)
        
    except Exception as e:
        small_log(f"ä¿å­˜{symbol}ç¼“å­˜å¤±è´¥: {e}")

def load_from_cache(symbol):
    """ä»ç¼“å­˜åŠ è½½æ•°æ®"""
    try:
        cache_file = get_cache_file_path(symbol)
        if os.path.exists(cache_file):
            # ç¡®ä¿æ—¥æœŸç´¢å¼•æ­£ç¡®è§£æ
            df = pd.read_csv(cache_file, index_col=0)
            df.index = pd.to_datetime(df.index)
            return df
    except Exception as e:
        small_log(f"åŠ è½½{symbol}ç¼“å­˜å¤±è´¥: {e}")
    return None

# è·å–ETFæ•°æ®çš„å‡½æ•°
def fetch_etf_data(symbol="510300"):
    # æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ
    if is_cache_valid(symbol):
        cached_data = load_from_cache(symbol)
        if cached_data is not None:
            small_log(f"ä½¿ç”¨{symbol}ç¼“å­˜æ•°æ®")
            return cached_data
    
    # ç¼“å­˜æ— æ•ˆæˆ–ä¸å­˜åœ¨ï¼Œä»APIè·å–æ•°æ®
    small_log(f"ä»APIè·å–{symbol}æ•°æ®...")
    try:
        # ä½¿ç”¨ akshare çš„ fund_etf_hist_em æ¥å£è·å– ETF æ•°æ®
        df = ak.fund_etf_hist_em(symbol=symbol, period="daily", adjust='qfq')
        # è½¬æ¢æ—¥æœŸæ ¼å¼
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])  # å‡è®¾æ—¥æœŸåˆ—åä¸º 'æ—¥æœŸ'
        df.set_index('æ—¥æœŸ', inplace=True)
        # é‡å‘½ååˆ—ä»¥ç¬¦åˆæ ‡å‡†æ ¼å¼
        df.rename(columns={
            'å¼€ç›˜': 'Open',
            'æœ€é«˜': 'High',
            'æœ€ä½': 'Low',
            'æ”¶ç›˜': 'Close',
            'æˆäº¤é‡': 'Volume'
        }, inplace=True)
        
        # ç¡®ä¿ç´¢å¼•æ˜¯datetimeç±»å‹
        df.index = pd.to_datetime(df.index)
        
        # ä¿å­˜åˆ°ç¼“å­˜
        save_to_cache(symbol, df)
        return df
        
    except Exception as e:
        small_log(f"è·å–{symbol}æ•°æ®å¤±è´¥: {e}")
        # å°è¯•ä½¿ç”¨ç¼“å­˜æ•°æ®ï¼ˆå³ä½¿ä¸æ˜¯ä»Šå¤©çš„ï¼‰
        cached_data = load_from_cache(symbol)
        if cached_data is not None:
            small_log(f"ä½¿ç”¨{symbol}å†å²ç¼“å­˜æ•°æ®")
            return cached_data
        return pd.DataFrame()

# è®¡ç®—åŠ¨é‡å’Œå‡çº¿
def calculate_momentum_and_ma(df, momentum_period=20, ma_period=28):
    # è®¡ç®—åŠ¨é‡ï¼šå½“å‰æ”¶ç›˜ä»·ä¸20å¤©å‰æ”¶ç›˜ä»·çš„ç™¾åˆ†æ¯”å˜åŒ–
    df['Momentum'] = df['Close'] / df['Close'].shift(momentum_period) - 1
    # è®¡ç®—28å¤©å‡çº¿
    df['MA'] = df['Close'].rolling(window=ma_period).mean()
    return df

# ç­›é€‰ç¬¦åˆæ¡ä»¶çš„ETF
def select_etfs(etf_list, etf_names, momentum_period=20, ma_period=28):
    etf_data = {}
    for symbol in etf_list:
        try:
            df = fetch_etf_data(symbol)
            if df.empty:
                small_log(f"{symbol} æ•°æ®ä¸ºç©ºï¼Œå·²è·³è¿‡")
                continue
            df = calculate_momentum_and_ma(df, momentum_period, ma_period)
            etf_data[symbol] = df
        except Exception as e:
            small_log(f"å¤„ç†{symbol}æ•°æ®å¤±è´¥: {e}")
            continue
    
    if not etf_data:
        small_log("æ— æ³•è·å–ä»»ä½•ETFæ•°æ®")
        return [], []
    
    # è·å–æœ€æ–°çš„æ•°æ®
    latest_data = {symbol: df.iloc[-1] for symbol, df in etf_data.items()}
    
    # æ”¶é›†æ‰€æœ‰ETFçš„åŠ¨é‡å’Œæ˜¯å¦å¤§äºå‡çº¿çš„ä¿¡æ¯
    all_etfs = []
    for symbol, data in latest_data.items():
        above_ma = data['Close'] > data['MA']
        all_etfs.append((symbol, etf_names[symbol], data['Close'], data['MA'], data['Momentum'], above_ma))
    
    # æŒ‰åŠ¨é‡æ’åº
    all_etfs.sort(key=lambda x: x[4], reverse=True)
    
    # é€‰æ‹©åŠ¨é‡æ’åå‰ä¸¤ä½ä¸”æ”¶ç›˜ä»·å¤§äºå‡çº¿çš„ETF
    selected_etfs = [(etf[0], etf[1], etf[2], etf[3], etf[4]) for etf in all_etfs if etf[5]][:2]
    return selected_etfs, all_etfs

# å›æµ‹å‡½æ•°
def backtest_strategy(etf_list, etf_names, start_date, end_date, momentum_period=20, ma_period=28, max_positions=2):
    """å›æµ‹åŠ¨é‡ç­–ç•¥"""
    # è½¬æ¢æ—¥æœŸç±»å‹
    start_date = pd.to_datetime(start_date)
    end_date = pd.to_datetime(end_date)
    
    # è·å–æ‰€æœ‰ETFçš„å†å²æ•°æ®
    etf_data = {}
    for symbol in etf_list:
        try:
            df = fetch_etf_data(symbol)
            if df.empty:
                continue
            # ç­›é€‰æ—¶é—´èŒƒå›´
            df = df[(df.index >= start_date) & (df.index <= end_date)]
            if len(df) < max(momentum_period, ma_period) + 10:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®
                continue
            df = calculate_momentum_and_ma(df, momentum_period, ma_period)
            etf_data[symbol] = df
        except Exception as e:
            small_log(f"å¤„ç†{symbol}æ•°æ®å¤±è´¥: {e}")
            continue
    
    if len(etf_data) < 2:
        small_log("å¯ç”¨ETFæ•°é‡ä¸è¶³2åªï¼Œæ— æ³•å›æµ‹")
        return None, None, None
    
    # è·å–æ‰€æœ‰ETFçš„å…±åŒæ—¥æœŸ
    common_dates = None
    for symbol, df in etf_data.items():
        if common_dates is None:
            common_dates = set(df.index)
        else:
            common_dates = common_dates.intersection(set(df.index))
    
    if len(common_dates) < 30:
        small_log("å…±åŒäº¤æ˜“æ—¥ä¸è¶³30å¤©ï¼Œæ— æ³•å›æµ‹")
        return None, None, None
    
    common_dates = sorted(list(common_dates))
    
    # å›æµ‹é€»è¾‘
    # åˆå§‹åŒ–æŠ•èµ„ç»„åˆå‡€å€¼ï¼Œä»ç¬¬ä¸€ä¸ªæœ‰æ•ˆäº¤æ˜“æ—¥å¼€å§‹
    start_index = max(momentum_period, ma_period)
    portfolio_values = [1.0]  # åˆå§‹å‡€å€¼1.0
    holdings_history = []  # æŒä»“å†å²
    trade_history = []  # äº¤æ˜“å†å²
    
    current_holdings = set()  # å½“å‰æŒä»“
    
    for i, date in enumerate(common_dates):
        if i < start_index:
            # å‰Nå¤©æ•°æ®ä¸è¶³ï¼Œè·³è¿‡
            continue
        
        # è®¡ç®—å½“æ—¥åŠ¨é‡æ’å
        momentums = {}
        candidates = []
        
        for symbol, df in etf_data.items():
            if date in df.index:
                row = df.loc[date]
                if not pd.isna(row['Close']) and not pd.isna(row['MA']) and not pd.isna(row['Momentum']):
                    if row['Close'] > row['MA']:
                        candidates.append(symbol)
                        momentums[symbol] = row['Momentum']
        
        # æŒ‰åŠ¨é‡æ’åºï¼Œå–å‰Nå
        if candidates:
            sorted_candidates = sorted(candidates, key=lambda x: momentums[x], reverse=True)
            top_candidates = sorted_candidates[:max_positions]
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒä»“
            to_sell = current_holdings - set(top_candidates)
            to_buy = set(top_candidates) - current_holdings
            
            # è®°å½•äº¤æ˜“
            for etf in to_sell:
                trade_history.append({
                    'æ—¥æœŸ': date.strftime('%Y-%m-%d'),
                    'ETFä»£ç ': etf,
                    'ETFåç§°': etf_names[etf],
                    'æ“ä½œ': 'å–å‡º',
                    'ä»·æ ¼': etf_data[etf].loc[date, 'Close']
                })
            
            for etf in to_buy:
                trade_history.append({
                    'æ—¥æœŸ': date.strftime('%Y-%m-%d'),
                    'ETFä»£ç ': etf,
                    'ETFåç§°': etf_names[etf],
                    'æ“ä½œ': 'ä¹°å…¥',
                    'ä»·æ ¼': etf_data[etf].loc[date, 'Close']
                })
            
            # æ›´æ–°æŒä»“
            current_holdings = set(top_candidates)
        else:
            # æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„ETFï¼Œæ¸…ä»“
            for etf in current_holdings:
                trade_history.append({
                    'æ—¥æœŸ': date.strftime('%Y-%m-%d'),
                    'ETFä»£ç ': etf,
                    'ETFåç§°': etf_names[etf],
                    'æ“ä½œ': 'å–å‡º',
                    'ä»·æ ¼': etf_data[etf].loc[date, 'Close']
                })
            current_holdings = set()
        
        # è®°å½•æŒä»“
        holdings_history.append({
            'æ—¥æœŸ': date.strftime('%Y-%m-%d'),
            'æŒä»“ETF': list(current_holdings),
            'æŒä»“æ•°é‡': len(current_holdings)
        })
        
        # è®¡ç®—å½“æ—¥æ”¶ç›Š
        if i > 0 and current_holdings:
            # è®¡ç®—æŒä»“ETFçš„å¹³å‡æ”¶ç›Š
            daily_returns = []
            for etf in current_holdings:
                if i > 0:
                    prev_date = common_dates[i-1]
                    if prev_date in etf_data[etf].index and date in etf_data[etf].index:
                        prev_price = etf_data[etf].loc[prev_date, 'Close']
                        curr_price = etf_data[etf].loc[date, 'Close']
                        if prev_price > 0:
                            daily_return = (curr_price / prev_price - 1)
                            daily_returns.append(daily_return)
            
            if daily_returns:
                # è®¡ç®—å¹³å‡æ”¶ç›Š
                avg_daily_return = sum(daily_returns) / len(daily_returns)
                portfolio_values.append(portfolio_values[-1] * (1 + avg_daily_return))
            else:
                portfolio_values.append(portfolio_values[-1])
        else:
            portfolio_values.append(portfolio_values[-1])
    
    # è®¡ç®—å›æµ‹æŒ‡æ ‡
    if len(portfolio_values) > 1:
        # ç¡®ä¿é¦–æœ«å‡€å€¼ä¸æ—¥æœŸä¸€ä¸€å¯¹åº”
        start_value = portfolio_values[0]
        end_value = portfolio_values[-1]
        total_return = (end_value / start_value - 1) * 100
        # ä½¿ç”¨æ­£ç¡®çš„èµ·å§‹æ—¥æœŸè®¡ç®—å¤©æ•°
        start_date_index = max(momentum_period, ma_period)
        days = (common_dates[-1] - common_dates[start_date_index]).days
        annual_return = calculate_annual_return(start_value, end_value, days)
        max_drawdown = calculate_max_drawdown(portfolio_values)
        sharpe_ratio = calculate_sharpe_ratio(portfolio_values)
    else:
        total_return = 0
        annual_return = 0
        max_drawdown = 0
        sharpe_ratio = 0
    
    return {
        'portfolio_values': portfolio_values,
        'dates': [d.strftime('%Y-%m-%d') for d in common_dates[max(momentum_period, ma_period):]],
        'total_return': total_return,  # æ€»æ”¶ç›Šç‡=é¦–æœ«å‡€å€¼ä¹‹æ¯”-1
        'annual_return': annual_return,
        'max_drawdown': max_drawdown,
        'sharpe_ratio': sharpe_ratio,
        'trade_count': len(trade_history)
    }, trade_history, holdings_history

def calculate_annual_return(start_value, end_value, days):
    """è®¡ç®—å¹´åŒ–æ”¶ç›Šç‡"""
    if days <= 0 or start_value <= 0:
        return 0
    years = days / 365.25
    # ä½¿ç”¨æ›´ç¨³å®šçš„å¹´åŒ–æ”¶ç›Šç‡è®¡ç®—æ–¹æ³•
    if years > 0:
        return ((end_value / start_value) ** (1 / years) - 1) * 100
    else:
        return 0

def calculate_max_drawdown(values):
    """è®¡ç®—æœ€å¤§å›æ’¤"""
    if len(values) < 2:
        return 0
    
    max_dd = 0
    peak = values[0]
    
    for value in values:
        if value > peak:
            peak = value
        dd = (peak - value) / peak * 100
        if dd > max_dd:
            max_dd = dd
    
    return max_dd

def calculate_sharpe_ratio(values):
    """è®¡ç®—å¤æ™®æ¯”ç‡"""
    if len(values) < 2:
        return 0
    
    returns = []
    for i in range(1, len(values)):
        if values[i-1] > 0:
            returns.append((values[i] / values[i-1] - 1) * 100)
    
    if not returns:
        return 0
    
    mean_return = np.mean(returns)
    std_return = np.std(returns)
    
    if std_return == 0:
        return 0
    
    # å‡è®¾æ— é£é™©åˆ©ç‡ä¸º3%
    risk_free_rate = 3
    sharpe = (mean_return - risk_free_rate) / std_return * np.sqrt(252)
    
    return sharpe

def small_log(msg):
    # å¦‚æœæ˜¯ç¼“å­˜ç›¸å…³çš„æ—¥å¿—ä¸”è®¾ç½®ä¸ºä¸æ˜¾ç¤ºï¼Œåˆ™è·³è¿‡
    if not SHOW_CACHE_LOGS and ("ç¼“å­˜" in msg or "ä½¿ç”¨" in msg and "æ•°æ®" in msg):
        return
    st.markdown(f"<div style='font-size:12px; color:#888;'>{msg}</div>", unsafe_allow_html=True)

# ä¿®æ”¹é¡µé¢æ ‡é¢˜
st.title("ğŸ”„ å¤§ç±»èµ„äº§è½®åŠ¨")

st.markdown("""
> æœ¬å·¥å…·åŸºäºåŠ¨é‡ä¸å‡çº¿ç­–ç•¥ï¼Œè‡ªåŠ¨æ¨èå¤§ç±»èµ„äº§ï¼ˆETFï¼‰è½®åŠ¨æŒä»“ã€‚
> 
> - **åŠ¨é‡ç­›é€‰**ï¼šä¼˜å…ˆé€‰æ‹©è¿‘æœŸæ¶¨å¹…é å‰çš„èµ„äº§
> - **å‡çº¿è¿‡æ»¤**ï¼šä»…æŒæœ‰ä»·æ ¼é«˜äºå‡çº¿çš„èµ„äº§
> - **ç­‰æƒåˆ†é…**ï¼šæŒä»“èµ„äº§ç­‰æƒé‡åˆ†é…ï¼Œä¾¿äºå®ç›˜è·Ÿè¸ª
""")
st.markdown("---")

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="å¤§ç±»èµ„äº§è½®åŠ¨",
    page_icon="ğŸ”„",
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ˜¾ç¤ºç¼“å­˜ä¿¡æ¯
st.sidebar.subheader("ç¼“å­˜ä¿¡æ¯")
meta_data = load_cache_meta()
if meta_data:
    st.sidebar.write("**å·²ç¼“å­˜çš„ETFï¼š**")
    for symbol, info in meta_data.items():
        st.sidebar.write(f"- {symbol}: {info.get('last_update', 'N/A')}")
    
    # æ¸…é™¤ç¼“å­˜æŒ‰é’®
    if st.sidebar.button("æ¸…é™¤æ‰€æœ‰ç¼“å­˜"):
        try:
            for file in os.listdir(CACHE_DIR):
                file_path = os.path.join(CACHE_DIR, file)
                if os.path.isfile(file_path):
                    os.remove(file_path)
            st.sidebar.success("ç¼“å­˜å·²æ¸…é™¤")
            st.rerun()
        except Exception as e:
            st.sidebar.error(f"æ¸…é™¤ç¼“å­˜å¤±è´¥: {e}")
else:
    small_log("æš‚æ— ç¼“å­˜æ•°æ®")

# ETFæ± é€‰æ‹©
etf_list = list(DEFAULT_ETF_POOL.keys())
all_etfs = DEFAULT_ETF_POOL

# ä¿®å¤defaultç±»å‹å’Œå†…å®¹
raw_default = list(DEFAULT_ETF_POOL.keys())
if etf_list and raw_default:
    default = [type(etf_list[0])(x) for x in raw_default]
    default = [x for x in default if x in etf_list]
else:
    default = []

st.markdown("**é€‰æ‹©æŒ‡æ•°æ± ï¼ˆå¯å¤šé€‰ï¼Œé»˜è®¤6åªï¼‰ï¼š**")
selected_etfs = st.multiselect(
    "ETFæ± ",
    options=list(all_etfs.keys()),
    default=default,
    format_func=lambda x: f"{x} - {all_etfs.get(x, x)}"
)

# ç­–ç•¥å‚æ•°
col1, col2, col3 = st.columns(3)
with col1:
    momentum_period = st.number_input("åŠ¨é‡å‘¨æœŸ", min_value=5, max_value=60, value=20)
with col2:
    ma_period = st.number_input("å‡çº¿å‘¨æœŸ", min_value=5, max_value=60, value=28)
with col3:
    max_positions = st.number_input("æœ€å¤§æŒä»“æ•°é‡", min_value=1, max_value=5, value=2)

# è‡ªåŠ¨è®¡ç®—é€»è¾‘
def auto_calculate_momentum():
    """è‡ªåŠ¨è®¡ç®—åŠ¨é‡ç­–ç•¥ç»“æœ"""
    if len(selected_etfs) < 2:
        st.warning("è¯·è‡³å°‘é€‰æ‹©2åªETF")
        return None, None
    
    with st.spinner("æ­£åœ¨è·å–ETFæ•°æ®å¹¶è®¡ç®—æŒä»“..."):
        try:
            selected_etfs_result, all_etfs_result = select_etfs(selected_etfs, all_etfs, momentum_period, ma_period)
            return selected_etfs_result, all_etfs_result
        except Exception as e:
            st.error(f"è®¡ç®—å¤±è´¥: {e}")
            import traceback
            st.markdown("<div style='font-size:12px; color:#888;'>" + traceback.format_exc().replace('\n', '<br>') + "</div>", unsafe_allow_html=True)
            return None, None

# æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°è®¡ç®—
current_params = {
    'selected_etfs': selected_etfs,
    'momentum_period': momentum_period,
    'ma_period': ma_period,
    'max_positions': max_positions
}

# å¦‚æœå‚æ•°å‘ç”Ÿå˜åŒ–æˆ–æ²¡æœ‰ç¼“å­˜ç»“æœï¼Œåˆ™é‡æ–°è®¡ç®—
if ('momentum_params' not in st.session_state or 
    st.session_state.momentum_params != current_params or
    'momentum_results' not in st.session_state):
    
    st.session_state.momentum_params = current_params
    selected_etfs_result, all_etfs_result = auto_calculate_momentum()
    st.session_state.momentum_results = {
        'selected_etfs_result': selected_etfs_result,
        'all_etfs_result': all_etfs_result
    }
else:
    # ä½¿ç”¨ç¼“å­˜çš„ç»“æœ
    selected_etfs_result = st.session_state.momentum_results['selected_etfs_result']
    all_etfs_result = st.session_state.momentum_results['all_etfs_result']

# æ˜¾ç¤ºç»“æœ
if selected_etfs_result is not None and all_etfs_result is not None:
    st.markdown("---")
    st.subheader("âœ… æ¨èæŒä»“")
    if selected_etfs_result:
        holdings_data = []
        for symbol, name, close, ma, momentum in selected_etfs_result:
            holdings_data.append({
                'ETFä»£ç ': symbol,
                'ETFåç§°': name,
                'å½“å‰ä»·æ ¼(å…ƒ)': f"{close:.2f}",
                f'{ma_period}æ—¥å‡çº¿': f"{ma:.2f}",
                'ä»·æ ¼-å‡çº¿': f"{close - ma:.2f}",
                f'{momentum_period}æ—¥åŠ¨é‡': f"{momentum*100:.2f}%",
                'æŒä»“æƒé‡': f"{100/len(selected_etfs_result):.1f}%"
            })
        holdings_df = pd.DataFrame(holdings_data)
        st.dataframe(holdings_df.style.background_gradient(cmap="Greens"), use_container_width=True)
        st.success(f"æ¨èæŒæœ‰ {len(selected_etfs_result)} åªETFï¼Œç­‰æƒé‡åˆ†é…")
        
        # æ·»åŠ æ‰€æœ‰ETFåŠ¨é‡æ’åè¡¨æ ¼
        st.markdown("---")
        st.subheader("ğŸ“Š æ‰€æœ‰ETFåŠ¨é‡æ’å")
        all_etfs_data = []
        for symbol, name, close, ma, momentum, above_ma in all_etfs_result:
            all_etfs_data.append({
                'ETFä»£ç ': symbol,
                'ETFåç§°': name,
                'å½“å‰ä»·æ ¼(å…ƒ)': f"{close:.2f}",
                f'{ma_period}æ—¥å‡çº¿': f"{ma:.2f}",
                'ä»·æ ¼-å‡çº¿': f"{close - ma:.2f}",
                f'{momentum_period}æ—¥åŠ¨é‡': f"{momentum*100:.2f}%",
                'ç«™ä¸Šå‡çº¿': 'âœ…' if above_ma else 'âŒ',
                'æ¨è': 'â­' if (symbol, name, close, ma, momentum) in selected_etfs_result else ''
            })
        all_etfs_df = pd.DataFrame(all_etfs_data)
        all_etfs_df = all_etfs_df.sort_values(f'{momentum_period}æ—¥åŠ¨é‡', ascending=False, key=lambda x: pd.to_numeric(x.str.rstrip('%'), errors='coerce'))
        st.dataframe(all_etfs_df.style.background_gradient(cmap="Blues"), use_container_width=True)
        st.info("åŠ¨é‡æ’åä»…ä¾›å‚è€ƒï¼Œå»ºè®®ç»“åˆè‡ªèº«é£é™©åå¥½å†³ç­–ã€‚")
        
        # æ·»åŠ æ¨ªå‘æŸ±çŠ¶å›¾ï¼šåŠ¨é‡å¯¹æ¯”
        st.markdown("---")
        st.subheader("ğŸ“Š åŠ¨é‡å¯¹æ¯”æŸ±çŠ¶å›¾")
        
        # å‡†å¤‡æŸ±çŠ¶å›¾æ•°æ®
        bar_data = []
        for symbol, name, close, ma, momentum, above_ma in all_etfs_result:
            bar_data.append({
                'ETFä»£ç ': symbol,
                'ETFåç§°': name,
                'åŠ¨é‡å€¼': momentum * 100,  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
                'ç«™ä¸Šå‡çº¿': above_ma
            })
        
        bar_df = pd.DataFrame(bar_data)
        bar_df = bar_df.sort_values('åŠ¨é‡å€¼', ascending=True)  # å‡åºæ’åˆ—ï¼Œä¾¿äºæ¨ªå‘æ˜¾ç¤º
        
        # åˆ›å»ºæ¨ªå‘æŸ±çŠ¶å›¾
        fig_bar = go.Figure()
        
        for _, row in bar_df.iterrows():
            # æ ¹æ®åŠ¨é‡å€¼é€‰æ‹©é¢œè‰²ï¼šçº¢è‰²è¡¨ç¤ºæ­£åŠ¨é‡ï¼Œç»¿è‰²è¡¨ç¤ºè´ŸåŠ¨é‡
            if row['åŠ¨é‡å€¼'] > 0:
                color = '#d32f2f'  # çº¢è‰²è¡¨ç¤ºæ­£åŠ¨é‡
            elif row['åŠ¨é‡å€¼'] < 0:
                color = '#388e3c'  # ç»¿è‰²è¡¨ç¤ºè´ŸåŠ¨é‡
            else:
                color = '#666666'  # ç°è‰²è¡¨ç¤ºé›¶åŠ¨é‡
            
            fig_bar.add_trace(go.Bar(
                y=[f"{row['ETFä»£ç ']} - {row['ETFåç§°']}"],
                x=[row['åŠ¨é‡å€¼']],
                orientation='h',
                marker_color=color,
                name=f"{row['ETFä»£ç ']} - {row['ETFåç§°']}",
                hovertemplate='<b>%{y}</b><br>' +
                            'åŠ¨é‡å€¼: %{x:.2f}%<br>' +
                            'çŠ¶æ€: ' + ('âœ… ç«™ä¸Šå‡çº¿' if row['ç«™ä¸Šå‡çº¿'] else 'âŒ æœªç«™ä¸Šå‡çº¿') + '<br>' +
                            '<extra></extra>'
            ))
        
        # è®¾ç½®å›¾è¡¨æ ·å¼
        fig_bar.update_layout(
            title_text='ETFåŠ¨é‡å¯¹æ¯”',
            title_x=0.5,
            font_size=12,
            showlegend=False,
            xaxis_title='åŠ¨é‡å€¼ (%)',
            yaxis_title='ETF',
            height=400,
            xaxis_tickformat=",.2f",
            hovermode='closest'
        )
        
        # æ·»åŠ é›¶çº¿
        fig_bar.add_vline(x=0, line_width=1, line_dash="dash", line_color="#666666", opacity=0.7)
        
        # æ˜¾ç¤ºæŸ±çŠ¶å›¾
        st.plotly_chart(fig_bar, use_container_width=True)
        
        # æ·»åŠ æŸ±çŠ¶å›¾è¯´æ˜
        st.info("""
        **æŸ±çŠ¶å›¾è¯´æ˜ï¼š**
        - çº¢è‰²æŸ±ï¼šæ­£åŠ¨é‡ï¼ˆä»·æ ¼ä¸Šæ¶¨è¶‹åŠ¿ï¼‰
        - ç»¿è‰²æŸ±ï¼šè´ŸåŠ¨é‡ï¼ˆä»·æ ¼ä¸‹è·Œè¶‹åŠ¿ï¼‰
        - ç°è‰²æŸ±ï¼šé›¶åŠ¨é‡ï¼ˆä»·æ ¼æ— å˜åŒ–ï¼‰
        - æŸ±é•¿è¡¨ç¤ºåŠ¨é‡å€¼å¤§å°
        - é›¶çº¿å·¦ä¾§ä¸ºè´ŸåŠ¨é‡ï¼Œå³ä¾§ä¸ºæ­£åŠ¨é‡
        - çŠ¶æ€åˆ—æ˜¾ç¤ºæ˜¯å¦ç«™ä¸Šå‡çº¿ï¼ˆâœ…ç«™ä¸Šï¼ŒâŒæœªç«™ä¸Šï¼‰
        """)
        
        # æ·»åŠ è¶‹åŠ¿å›¾ï¼šå±•ç¤ºè¿‘ä¸€å¹´æ ‡çš„æœ¬èº«çš„èµ°åŠ¿
        st.markdown("---")
        st.subheader("ğŸ“ˆ è¿‘ä¸€å¹´èµ°åŠ¿è¶‹åŠ¿å›¾")
        
        # è®¡ç®—è¿‘ä¸€å¹´çš„ç´¯è®¡æ¶¨è·Œå¹…
        end_date = datetime.now()
        start_date = end_date - timedelta(days=365)
        
        # åˆ›å»ºè¶‹åŠ¿å›¾
        fig = go.Figure()
        
        # å®šä¹‰é¢œè‰²æ–¹æ¡ˆ - ä½¿ç”¨ç¡®å®šå­˜åœ¨çš„é¢œè‰²
        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', 
                 '#e377c2', '#7f7f7f', '#bcbd22', '#17becf', '#a6cee3', '#fb9a99',
                 '#fdbf6f', '#cab2d6', '#ffff99', '#b15928', '#fccde5', '#d9d9d9']
        
        # æ”¶é›†æ‰€æœ‰æ•°æ®ç”¨äºè®¡ç®—yè½´èŒƒå›´
        all_cumulative_returns = []
        
        # æ”¶é›†æ‰€æœ‰ETFçš„ç´¯è®¡æ”¶ç›Šæ•°æ®ç”¨äºè®¡ç®—ç­‰æƒé…ç½®
        etf_returns_data = {}
        
        for i, (symbol, name, _, _, _, _) in enumerate(all_etfs_result):
            try:
                # è·å–å†å²æ•°æ®
                df = fetch_etf_data(symbol)
                if not df.empty:
                    # ç­›é€‰è¿‘ä¸€å¹´æ•°æ®
                    df_filtered = df[(df.index >= start_date) & (df.index <= end_date)]
                    if not df_filtered.empty:
                        # è®¡ç®—ç´¯è®¡æ¶¨è·Œå¹…ï¼ˆä»¥å¹´åˆä¸ºåŸºå‡†ï¼‰
                        first_price = df_filtered.iloc[0]['Close']
                        cumulative_returns = (df_filtered['Close'] / first_price - 1) * 100
                        all_cumulative_returns.extend(cumulative_returns.tolist())
                        
                        # å­˜å‚¨æ•°æ®ç”¨äºè®¡ç®—ç­‰æƒé…ç½®
                        etf_returns_data[symbol] = {
                            'dates': df_filtered.index,
                            'returns': cumulative_returns,
                            'name': f"{symbol} - {name}"
                        }
                        
                        # ç»˜åˆ¶è¶‹åŠ¿çº¿ï¼Œä½¿ç”¨å¾ªç¯é¢œè‰²
                        color = colors[i % len(colors)]
                        fig.add_trace(go.Scatter(
                            x=df_filtered.index, 
                            y=cumulative_returns,
                            mode='lines+markers', 
                            name=f"{symbol} - {name}", 
                            line=dict(color=color, width=2), 
                            marker=dict(size=3),
                            hovertemplate='<b>%{fullData.name}</b><br>' +
                                        'æ—¶é—´: %{x}<br>' +
                                        'ç´¯è®¡æ¶¨è·Œå¹…: %{y:.2f}%<br>' +
                                        '<extra></extra>'
                        ))
                        
            except Exception as e:
                st.warning(f"è·å– {symbol} è¶‹åŠ¿æ•°æ®å¤±è´¥: {e}")
                continue
        
        # è®¡ç®—å¹¶ç»˜åˆ¶ç­‰æƒé…ç½®æ”¶ç›Šæ›²çº¿
        if len(etf_returns_data) > 1:
            try:
                # æ‰¾åˆ°æ‰€æœ‰ETFçš„å…±åŒæ—¥æœŸ
                common_dates = None
                for symbol, data in etf_returns_data.items():
                    if common_dates is None:
                        common_dates = set(data['dates'])
                    else:
                        common_dates = common_dates.intersection(set(data['dates']))
                
                if common_dates and len(common_dates) > 10:
                    common_dates = sorted(list(common_dates))
                    
                    # è®¡ç®—ç­‰æƒé…ç½®çš„ç´¯è®¡æ”¶ç›Š
                    equal_weight_returns = []
                    for date in common_dates:
                        daily_return = 0
                        valid_returns = 0
                        for symbol, data in etf_returns_data.items():
                            if date in data['dates']:
                                # æ‰¾åˆ°è¯¥æ—¥æœŸå¯¹åº”çš„æ”¶ç›Šç‡
                                date_idx = data['dates'].get_loc(date)
                                if date_idx > 0:  # ä¸æ˜¯ç¬¬ä¸€ä¸ªæ•°æ®ç‚¹
                                    prev_date_idx = date_idx - 1
                                    prev_date = data['dates'][prev_date_idx]
                                    if prev_date in data['dates']:
                                        prev_return = data['returns'].iloc[prev_date_idx]
                                        curr_return = data['returns'].iloc[date_idx]
                                        # è®¡ç®—æ—¥æ”¶ç›Šç‡
                                        daily_return += (curr_return - prev_return) / 100  # è½¬æ¢ä¸ºå°æ•°
                                        valid_returns += 1
                        
                        if valid_returns > 0:
                            # è®¡ç®—ç­‰æƒå¹³å‡æ—¥æ”¶ç›Šç‡
                            avg_daily_return = daily_return / valid_returns
                            if len(equal_weight_returns) == 0:
                                equal_weight_returns.append(0)  # èµ·å§‹ç‚¹ä¸º0%
                            else:
                                # ç´¯åŠ æ—¥æ”¶ç›Šç‡
                                equal_weight_returns.append(equal_weight_returns[-1] + avg_daily_return * 100)
                        else:
                            if len(equal_weight_returns) > 0:
                                equal_weight_returns.append(equal_weight_returns[-1])
                            else:
                                equal_weight_returns.append(0)
                    
                    # ç»˜åˆ¶ç­‰æƒé…ç½®æ›²çº¿
                    fig.add_trace(go.Scatter(
                        x=common_dates,
                        y=equal_weight_returns,
                        mode='lines+markers',
                        name='ğŸ† ç­‰æƒé…ç½®',
                        line=dict(color='#FF6B6B', width=3, dash='dash'),
                        marker=dict(size=4),
                        hovertemplate='<b>ğŸ† ç­‰æƒé…ç½®</b><br>' +
                                    'æ—¶é—´: %{x}<br>' +
                                    'ç´¯è®¡æ¶¨è·Œå¹…: %{y:.2f}%<br>' +
                                    '<extra></extra>'
                    ))
                    
                    # å°†ç­‰æƒé…ç½®æ•°æ®ä¹ŸåŠ å…¥yè½´èŒƒå›´è®¡ç®—
                    all_cumulative_returns.extend(equal_weight_returns)
                    
            except Exception as e:
                st.warning(f"è®¡ç®—ç­‰æƒé…ç½®æ”¶ç›Šå¤±è´¥: {e}")
        
        # æ·»åŠ é›¶çº¿ä½œä¸ºå‚è€ƒ
        fig.add_hline(y=0, line_width=1, line_dash="dash", line_color="#666666", opacity=0.7)
        
        # è®¾ç½®å›¾è¡¨æ ·å¼
        fig.update_layout(
            title_text='è¿‘ä¸€å¹´ç´¯è®¡æ¶¨è·Œå¹…è¶‹åŠ¿',
            title_x=0.5,
            font_size=14,
            showlegend=True,
            legend_orientation="v",  # æ”¹ä¸ºå‚ç›´å¸ƒå±€
            legend_x=1.02,  # æ”¾åœ¨å³ä¾§
            legend_y=0.5,   # å‚ç›´å±…ä¸­
            xaxis_title='æ—¶é—´',
            yaxis_title='ç´¯è®¡æ¶¨è·Œå¹… (%)',
            xaxis_tickangle=45,
            xaxis_tickformat="%Y-%m-%d",
            yaxis_tickformat=",.2f",
            hovermode='x unified',
            height=700  # å¢åŠ å›¾è¡¨é«˜åº¦åˆ°700px
        )
        
        # è®¾ç½®yè½´èŒƒå›´ï¼Œç¡®ä¿é›¶çº¿åœ¨ä¸­é—´
        if all_cumulative_returns:
            y_min = min(all_cumulative_returns)
            y_max = max(all_cumulative_returns)
            
            # è®¡ç®—åˆé€‚çš„Yè½´èŒƒå›´
            y_range = max(abs(y_min), abs(y_max))
            
            # å¦‚æœæ•°æ®èŒƒå›´å¤ªå°ï¼Œè®¾ç½®æœ€å°èŒƒå›´
            if y_range < 5:
                y_range = 10
            
            # è®¾ç½®Yè½´èŒƒå›´ï¼Œç»™æ•°æ®ç•™å‡ºé€‚å½“çš„è¾¹è·
            y_padding = y_range * 0.15  # 15%çš„è¾¹è·
            fig.update_layout(
                yaxis_range=[y_min - y_padding, y_max + y_padding]
            )
        
        # æ˜¾ç¤ºå›¾è¡¨
        st.plotly_chart(fig, use_container_width=True)
        
        # æ·»åŠ ç´¯è®¡æ¶¨è·Œå¹…å¯¹æ¯”æŸ±çŠ¶å›¾
        st.markdown("---")
        st.subheader("ğŸ“Š è¿‘ä¸€å¹´ç´¯è®¡æ¶¨è·Œå¹…å¯¹æ¯”")
        
        # å‡†å¤‡æŸ±çŠ¶å›¾æ•°æ®
        returns_bar_data = []
        for i, (symbol, name, _, _, _, _) in enumerate(all_etfs_result):
            try:
                # è·å–å†å²æ•°æ®
                df = fetch_etf_data(symbol)
                if not df.empty:
                    # ç­›é€‰è¿‘ä¸€å¹´æ•°æ®
                    df_filtered = df[(df.index >= start_date) & (df.index <= end_date)]
                    if not df_filtered.empty:
                        # è®¡ç®—ç´¯è®¡æ¶¨è·Œå¹…
                        first_price = df_filtered.iloc[0]['Close']
                        last_price = df_filtered.iloc[-1]['Close']
                        cumulative_return = (last_price / first_price - 1) * 100
                        
                        returns_bar_data.append({
                            'ETFä»£ç ': symbol,
                            'ETFåç§°': name,
                            'ç´¯è®¡æ¶¨è·Œå¹…': cumulative_return,
                            'é¢œè‰²': colors[i % len(colors)]  # ä½¿ç”¨ä¸è¶‹åŠ¿å›¾ç›¸åŒçš„é¢œè‰²
                        })
            except Exception as e:
                continue
        
        if returns_bar_data:
            returns_bar_df = pd.DataFrame(returns_bar_data)
            returns_bar_df = returns_bar_df.sort_values('ç´¯è®¡æ¶¨è·Œå¹…', ascending=True)  # å‡åºæ’åˆ—
            
            # åˆ›å»ºæ¨ªå‘æŸ±çŠ¶å›¾
            fig_returns_bar = go.Figure()
            
            for _, row in returns_bar_df.iterrows():
                fig_returns_bar.add_trace(go.Bar(
                    y=[f"{row['ETFä»£ç ']} - {row['ETFåç§°']}"],
                    x=[row['ç´¯è®¡æ¶¨è·Œå¹…']],
                    orientation='h',
                    marker_color=row['é¢œè‰²'],
                    name=f"{row['ETFä»£ç ']} - {row['ETFåç§°']}",
                    hovertemplate='<b>%{y}</b><br>' +
                                'ç´¯è®¡æ¶¨è·Œå¹…: %{x:.2f}%<br>' +
                                '<extra></extra>'
                ))
            
            # è®¾ç½®å›¾è¡¨æ ·å¼
            fig_returns_bar.update_layout(
                title_text='è¿‘ä¸€å¹´ç´¯è®¡æ¶¨è·Œå¹…å¯¹æ¯”',
                title_x=0.5,
                font_size=12,
                showlegend=False,
                xaxis_title='ç´¯è®¡æ¶¨è·Œå¹… (%)',
                yaxis_title='ETF',
                height=400,
                xaxis_tickformat=",.2f",
                hovermode='closest'
            )
            
            # æ·»åŠ é›¶çº¿
            fig_returns_bar.add_vline(x=0, line_width=1, line_dash="dash", line_color="#666666", opacity=0.7)
            
            # æ˜¾ç¤ºæŸ±çŠ¶å›¾
            st.plotly_chart(fig_returns_bar, use_container_width=True)
            
            # æ·»åŠ æŸ±çŠ¶å›¾è¯´æ˜
            st.info("""
            **ç´¯è®¡æ¶¨è·Œå¹…æŸ±çŠ¶å›¾è¯´æ˜ï¼š**
            - æŸ±é•¿è¡¨ç¤ºç´¯è®¡æ¶¨è·Œå¹…å¤§å°
            - é›¶çº¿å·¦ä¾§ä¸ºè´Ÿæ”¶ç›Šï¼Œå³ä¾§ä¸ºæ­£æ”¶ç›Š
            - é¢œè‰²ä¸ä¸Šæ–¹è¶‹åŠ¿å›¾ä¿æŒä¸€è‡´ï¼Œä¾¿äºå¯¹åº”
            - æŒ‰ç´¯è®¡æ¶¨è·Œå¹…æ’åºï¼Œä¾¿äºè¯†åˆ«è¡¨ç°æœ€å¥½å’Œæœ€å·®çš„ETF
            """)
        
        # æ·»åŠ æ ‡çš„ç›¸å…³å› å­åˆ†æ
        st.markdown("---")
        st.subheader("ğŸ” æ ‡çš„ç›¸å…³å› å­åˆ†æ")
        
        # è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
        try:
            # å‡†å¤‡æ”¶ç›Šç‡æ•°æ® - ä½¿ç”¨æ‰€æœ‰é€‰ä¸­çš„ETF
            returns_data = {}
            common_dates = None
            
            for symbol in selected_etfs:  # ä½¿ç”¨selected_etfsè€Œä¸æ˜¯all_etfs_result
                df = fetch_etf_data(symbol)
                if not df.empty:
                    # ç­›é€‰è¿‘ä¸€å¹´æ•°æ®
                    df_filtered = df[(df.index >= start_date) & (df.index <= end_date)]
                    if not df_filtered.empty:
                        # è®¡ç®—æ—¥æ”¶ç›Šç‡
                        df_filtered['Returns'] = df_filtered['Close'].pct_change()
                        returns_data[symbol] = df_filtered['Returns'].dropna()
                        
                        # æ‰¾åˆ°å…±åŒæ—¥æœŸ
                        if common_dates is None:
                            common_dates = set(returns_data[symbol].index)
                        else:
                            common_dates = common_dates.intersection(set(returns_data[symbol].index))
            
            if common_dates and len(common_dates) > 30:
                # å¯¹é½æ•°æ®
                aligned_returns = {}
                for symbol in returns_data:
                    aligned_returns[symbol] = returns_data[symbol].loc[list(common_dates)]
                
                # åˆ›å»ºæ”¶ç›Šç‡DataFrame
                returns_df = pd.DataFrame(aligned_returns)
                
                # è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
                correlation_matrix = returns_df.corr()
                
                # è®¡ç®—é£é™©æŒ‡æ ‡
                risk_metrics = {}
                for symbol in returns_df.columns:
                    returns = returns_df[symbol].dropna()
                    if len(returns) > 0:
                        # è®¡ç®—ç´¯ç§¯å‡€å€¼
                        cumulative_returns = (1 + returns).cumprod()
                        
                        # è·å–ETFåç§°
                        etf_name = all_etfs.get(symbol, symbol)
                        
                        risk_metrics[symbol] = {
                            'ETFåç§°': etf_name,
                            'å¹´åŒ–æ³¢åŠ¨ç‡': returns.std() * np.sqrt(252) * 100,
                            'å¹´åŒ–æ”¶ç›Šç‡': returns.mean() * 252 * 100,
                            'å¤æ™®æ¯”ç‡': (returns.mean() * 252 - 0.03) / (returns.std() * np.sqrt(252)) if returns.std() > 0 else 0,
                            'æœ€å¤§å›æ’¤': calculate_max_drawdown(cumulative_returns) * 100
                        }
                
                # æ˜¾ç¤ºç›¸å…³æ€§çƒ­åŠ›å›¾
                st.markdown("**ğŸ“Š ç›¸å…³æ€§çƒ­åŠ›å›¾**")
                
                # åˆ›å»ºå¸¦ETFåç§°çš„ç›¸å…³æ€§çŸ©é˜µ
                correlation_with_names = correlation_matrix.copy()
                correlation_with_names.columns = [f"{col} - {all_etfs.get(col, col)}" for col in correlation_with_names.columns]
                correlation_with_names.index = [f"{idx} - {all_etfs.get(idx, idx)}" for idx in correlation_with_names.index]
                
                fig_corr = go.Figure(data=go.Heatmap(
                    z=correlation_with_names.values,
                    x=correlation_with_names.columns,
                    y=correlation_with_names.index,
                    colorscale='RdBu',
                    zmid=0,
                    text=correlation_with_names.round(2).values,
                    texttemplate="%{text}",
                    textfont={"size": 10},
                    hoverongaps=False
                ))
                
                fig_corr.update_layout(
                    title_text='ETFæ—¥æ”¶ç›Šç‡ç›¸å…³æ€§çŸ©é˜µ',
                    title_x=0.5,
                    height=500,
                    xaxis_title='ETF',
                    yaxis_title='ETF'
                )
                
                st.plotly_chart(fig_corr, use_container_width=True)
                
                # æ˜¾ç¤ºé£é™©æŒ‡æ ‡è¡¨æ ¼
                st.markdown("**ğŸ“ˆ é£é™©æŒ‡æ ‡å¯¹æ¯”**")
                risk_df = pd.DataFrame(risk_metrics).T
                
                # æ ¼å¼åŒ–æ˜¾ç¤º - ç¡®ä¿ä¿ç•™2ä½å°æ•°
                formatted_risk_df = risk_df.copy()
                
                # å…ˆç¡®ä¿æ•°å€¼ç±»å‹æ­£ç¡®ï¼Œç„¶åè¿›è¡Œæ ¼å¼åŒ–
                formatted_risk_df['å¹´åŒ–æ³¢åŠ¨ç‡'] = pd.to_numeric(formatted_risk_df['å¹´åŒ–æ³¢åŠ¨ç‡'], errors='coerce').round(2).astype(str) + '%'
                formatted_risk_df['å¹´åŒ–æ”¶ç›Šç‡'] = pd.to_numeric(formatted_risk_df['å¹´åŒ–æ”¶ç›Šç‡'], errors='coerce').round(2).astype(str) + '%'
                formatted_risk_df['æœ€å¤§å›æ’¤'] = pd.to_numeric(formatted_risk_df['æœ€å¤§å›æ’¤'], errors='coerce').round(2).astype(str) + '%'
                formatted_risk_df['å¤æ™®æ¯”ç‡'] = pd.to_numeric(formatted_risk_df['å¤æ™®æ¯”ç‡'], errors='coerce').round(2)
                
                st.dataframe(formatted_risk_df, use_container_width=True)
                
                # ç›¸å…³æ€§åˆ†æè¯´æ˜
                st.info("""
                **ç›¸å…³å› å­åˆ†æè¯´æ˜ï¼š**
                - **ç›¸å…³æ€§çŸ©é˜µ**ï¼šæ•°å€¼è¶Šæ¥è¿‘1è¡¨ç¤ºæ­£ç›¸å…³è¶Šå¼ºï¼Œè¶Šæ¥è¿‘-1è¡¨ç¤ºè´Ÿç›¸å…³è¶Šå¼º
                - **å¹´åŒ–æ³¢åŠ¨ç‡**ï¼šåæ˜ ä»·æ ¼æ³¢åŠ¨é£é™©ï¼Œæ•°å€¼è¶Šå¤§é£é™©è¶Šé«˜
                - **å¹´åŒ–æ”¶ç›Šç‡**ï¼šå¹´åŒ–åçš„æ”¶ç›Šç‡è¡¨ç°
                - **å¤æ™®æ¯”ç‡**ï¼šé£é™©è°ƒæ•´åæ”¶ç›Šï¼Œæ•°å€¼è¶Šé«˜è¶Šå¥½ï¼ˆå‡è®¾æ— é£é™©åˆ©ç‡3%ï¼‰
                - **æœ€å¤§å›æ’¤**ï¼šå†å²æœ€å¤§ä¸‹è·Œå¹…åº¦ï¼Œåæ˜ ä¸‹è¡Œé£é™©
                """)
                
                # æŠ•èµ„ç»„åˆå»ºè®®
                st.markdown("**ğŸ’¡ æŠ•èµ„ç»„åˆå»ºè®®**")
                
                # æ‰¾å‡ºç›¸å…³æ€§æœ€ä½çš„ETFå¯¹
                min_corr = 1.0
                min_corr_pair = None
                for i in range(len(correlation_matrix.columns)):
                    for j in range(i+1, len(correlation_matrix.columns)):
                        corr_val = abs(correlation_matrix.iloc[i, j])
                        if corr_val < min_corr:
                            min_corr = corr_val
                            min_corr_pair = (correlation_matrix.columns[i], correlation_matrix.columns[j])
                
                if min_corr_pair:
                    st.success(f"**ä½ç›¸å…³æ€§ç»„åˆæ¨è**ï¼š{min_corr_pair[0]} å’Œ {min_corr_pair[1]} (ç›¸å…³æ€§: {min_corr:.3f})")
                
                # æ‰¾å‡ºå¤æ™®æ¯”ç‡æœ€é«˜çš„ETF
                best_sharpe = max(risk_metrics.items(), key=lambda x: x[1]['å¤æ™®æ¯”ç‡'])
                st.info(f"**æœ€ä½³é£é™©è°ƒæ•´æ”¶ç›Š**ï¼š{best_sharpe[0]} (å¤æ™®æ¯”ç‡: {best_sharpe[1]['å¤æ™®æ¯”ç‡']:.2f})")
                
            else:
                st.warning("æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œç›¸å…³å› å­åˆ†æ")
                
        except Exception as e:
            st.error(f"ç›¸å…³å› å­åˆ†æå¤±è´¥: {e}")
        
        # æ·»åŠ BIASè¶…ä¹°è¶…å–åˆ†æ
        st.markdown("---")
        st.subheader("ğŸ“Š BIASè¶…ä¹°è¶…å–åˆ†æ")
        
        try:
            # è®¡ç®—BIASæŒ‡æ ‡
            bias_data = []
            
            for symbol in selected_etfs:
                df = fetch_etf_data(symbol)
                if not df.empty:
                    # ç­›é€‰è¿‘ä¸€å¹´æ•°æ®
                    df_filtered = df[(df.index >= start_date) & (df.index <= end_date)]
                    if not df_filtered.empty:
                        # è®¡ç®—ä¸åŒå‘¨æœŸçš„BIAS
                        bias_6 = ((df_filtered['Close'] - df_filtered['Close'].rolling(6).mean()) / df_filtered['Close'].rolling(6).mean() * 100).iloc[-1]
                        bias_12 = ((df_filtered['Close'] - df_filtered['Close'].rolling(12).mean()) / df_filtered['Close'].rolling(12).mean() * 100).iloc[-1]
                        bias_24 = ((df_filtered['Close'] - df_filtered['Close'].rolling(24).mean()) / df_filtered['Close'].rolling(24).mean() * 100).iloc[-1]
                        
                        # è·å–å½“å‰ä»·æ ¼å’Œå‡çº¿
                        current_price = df_filtered['Close'].iloc[-1]
                        ma_6 = df_filtered['Close'].rolling(6).mean().iloc[-1]
                        ma_12 = df_filtered['Close'].rolling(12).mean().iloc[-1]
                        ma_24 = df_filtered['Close'].rolling(24).mean().iloc[-1]
                        
                        # åˆ¤æ–­è¶…ä¹°è¶…å–çŠ¶æ€
                        def get_bias_status(bias_6, bias_12, bias_24):
                            # ä½¿ç”¨ç»Ÿè®¡æ–¹æ³•è®¡ç®—åŠ¨æ€é˜ˆå€¼
                            # åŸºäºå†å²BIASæ•°æ®çš„æ ‡å‡†å·®æ¥è®¾ç½®é˜ˆå€¼
                            def calculate_dynamic_threshold(bias_values, multiplier=2.0):
                                """è®¡ç®—åŠ¨æ€é˜ˆå€¼ï¼šå‡å€¼ Â± (å€æ•° Ã— æ ‡å‡†å·®)"""
                                if len(bias_values) > 0:
                                    mean_bias = np.mean(bias_values)
                                    std_bias = np.std(bias_values)
                                    return mean_bias + multiplier * std_bias, mean_bias - multiplier * std_bias
                                return 5, -5  # é»˜è®¤å€¼
                            
                            # è·å–å†å²BIASæ•°æ®ç”¨äºè®¡ç®—åŠ¨æ€é˜ˆå€¼
                            try:
                                # è®¡ç®—è¿‡å»30ä¸ªäº¤æ˜“æ—¥çš„BIASå€¼
                                bias_6_history = ((df_filtered['Close'] - df_filtered['Close'].rolling(6).mean()) / df_filtered['Close'].rolling(6).mean() * 100).dropna().tail(30)
                                bias_12_history = ((df_filtered['Close'] - df_filtered['Close'].rolling(12).mean()) / df_filtered['Close'].rolling(12).mean() * 100).dropna().tail(30)
                                bias_24_history = ((df_filtered['Close'] - df_filtered['Close'].rolling(24).mean()) / df_filtered['Close'].rolling(24).mean() * 100).dropna().tail(30)
                                
                                # è®¡ç®—åŠ¨æ€é˜ˆå€¼
                                upper_6, lower_6 = calculate_dynamic_threshold(bias_6_history, 2.0)
                                upper_12, lower_12 = calculate_dynamic_threshold(bias_12_history, 2.0)
                                upper_24, lower_24 = calculate_dynamic_threshold(bias_24_history, 2.0)
                                
                                # ä½¿ç”¨åŠ¨æ€é˜ˆå€¼åˆ¤æ–­
                                if bias_6 > upper_6 and bias_12 > upper_12 and bias_24 > upper_24:
                                    return f"ğŸ”´ è¶…ä¹° (6æ—¥:{bias_6:.1f}%>{upper_6:.1f}%)", "danger"
                                elif bias_6 < lower_6 and bias_12 < lower_12 and bias_24 < lower_24:
                                    return f"ğŸŸ¢ è¶…å– (6æ—¥:{bias_6:.1f}%<{lower_6:.1f}%)", "success"
                                elif bias_6 > upper_6 * 0.8 or bias_12 > upper_12 * 0.8:
                                    return f"ğŸŸ¡ åè¶…ä¹° (6æ—¥:{bias_6:.1f}%)", "warning"
                                elif bias_6 < lower_6 * 0.8 or bias_12 < lower_12 * 0.8:
                                    return f"ğŸŸ  åè¶…å– (6æ—¥:{bias_6:.1f}%)", "warning"
                                else:
                                    return f"âšª æ­£å¸¸ (6æ—¥:{bias_6:.1f}%)", "info"
                                    
                            except:
                                # å¦‚æœåŠ¨æ€è®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿå›ºå®šé˜ˆå€¼
                                if bias_6 > 5 and bias_12 > 3 and bias_24 > 2:
                                    return "ğŸ”´ è¶…ä¹°", "danger"
                                elif bias_6 < -5 and bias_12 < -3 and bias_24 < -2:
                                    return "ğŸŸ¢ è¶…å–", "success"
                                elif bias_6 > 3 or bias_12 > 2:
                                    return "ğŸŸ¡ åè¶…ä¹°", "warning"
                                elif bias_6 < -3 or bias_12 < -2:
                                    return "ğŸŸ  åè¶…å–", "warning"
                                else:
                                    return "âšª æ­£å¸¸", "info"
                        
                        bias_status, status_color = get_bias_status(bias_6, bias_12, bias_24)
                        
                        bias_data.append({
                            'ETFä»£ç ': symbol,
                            'ETFåç§°': all_etfs.get(symbol, symbol),
                            'å½“å‰ä»·æ ¼': current_price,
                            '6æ—¥å‡çº¿': ma_6,
                            '12æ—¥å‡çº¿': ma_12,
                            '24æ—¥å‡çº¿': ma_24,
                            'BIAS(6)': bias_6,
                            'BIAS(12)': bias_12,
                            'BIAS(24)': bias_24,
                            'çŠ¶æ€': bias_status
                        })
            
            if bias_data:
                # åˆ›å»ºBIASåˆ†æè¡¨æ ¼
                bias_df = pd.DataFrame(bias_data)
                
                # æ ¼å¼åŒ–æ•°å€¼ï¼Œä¿ç•™2ä½å°æ•°
                bias_df['å½“å‰ä»·æ ¼'] = bias_df['å½“å‰ä»·æ ¼'].round(2)
                bias_df['6æ—¥å‡çº¿'] = bias_df['6æ—¥å‡çº¿'].round(2)
                bias_df['12æ—¥å‡çº¿'] = bias_df['12æ—¥å‡çº¿'].round(2)
                bias_df['24æ—¥å‡çº¿'] = bias_df['24æ—¥å‡çº¿'].round(2)
                bias_df['BIAS(6)'] = bias_df['BIAS(6)'].round(2)
                bias_df['BIAS(12)'] = bias_df['BIAS(12)'].round(2)
                bias_df['BIAS(24)'] = bias_df['BIAS(24)'].round(2)
                
                # æ·»åŠ ç™¾åˆ†æ¯”ç¬¦å·
                bias_df['BIAS(6)'] = bias_df['BIAS(6)'].astype(str) + '%'
                bias_df['BIAS(12)'] = bias_df['BIAS(12)'].astype(str) + '%'
                bias_df['BIAS(24)'] = bias_df['BIAS(24)'].astype(str) + '%'
                
                st.dataframe(bias_df, use_container_width=True)
                
                # æ·»åŠ BIASåˆ†æè¯´æ˜
                st.info("""
                **BIASè¶…ä¹°è¶…å–åˆ†æè¯´æ˜ï¼š**
                - **BIASæŒ‡æ ‡**ï¼šè¡¡é‡ä»·æ ¼åç¦»å‡çº¿çš„ç¨‹åº¦ï¼Œæ­£å€¼è¡¨ç¤ºä»·æ ¼é«˜äºå‡çº¿ï¼Œè´Ÿå€¼è¡¨ç¤ºä»·æ ¼ä½äºå‡çº¿
                - **åŠ¨æ€é˜ˆå€¼**ï¼šåŸºäºè¿‡å»30ä¸ªäº¤æ˜“æ—¥çš„BIASæ•°æ®ï¼Œä½¿ç”¨å‡å€¼Â±2å€æ ‡å‡†å·®è®¡ç®—è¶…ä¹°è¶…å–é˜ˆå€¼
                - **è¶…ä¹°çŠ¶æ€**ï¼šå½“å‰BIASå€¼è¶…è¿‡å†å²ç»Ÿè®¡ä¸Šé™ï¼Œå¯èƒ½é¢ä¸´å›è°ƒé£é™©
                - **è¶…å–çŠ¶æ€**ï¼šå½“å‰BIASå€¼ä½äºå†å²ç»Ÿè®¡ä¸‹é™ï¼Œå¯èƒ½å­˜åœ¨åå¼¹æœºä¼š
                - **ç»Ÿè®¡æ–¹æ³•**ï¼šé˜ˆå€¼ = å†å²å‡å€¼ Â± (2.0 Ã— å†å²æ ‡å‡†å·®)
                - **å¤‡ç”¨æ–¹æ¡ˆ**ï¼šå¦‚æœåŠ¨æ€è®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿå›ºå®šé˜ˆå€¼(Â±5%, Â±3%, Â±2%)
                """)
                
                # æŠ•èµ„å»ºè®®
                st.markdown("**ğŸ’¡ BIASæŠ•èµ„å»ºè®®**")
                
                # æ‰¾å‡ºè¶…ä¹°å’Œè¶…å–çš„ETF
                overbought_etfs = [row for row in bias_data if "è¶…ä¹°" in row['çŠ¶æ€']]
                oversold_etfs = [row for row in bias_data if "è¶…å–" in row['çŠ¶æ€']]
                
                if overbought_etfs:
                    overbought_text = ", ".join([f"{row['ETFä»£ç ']}({row['ETFåç§°']})" for row in overbought_etfs])
                    st.warning(f"**è¶…ä¹°ETF**ï¼š{overbought_text} - æ³¨æ„å›è°ƒé£é™©")
                
                if oversold_etfs:
                    oversold_text = ", ".join([f"{row['ETFä»£ç ']}({row['ETFåç§°']})" for row in oversold_etfs])
                    st.success(f"**è¶…å–ETF**ï¼š{oversold_text} - å…³æ³¨åå¼¹æœºä¼š")
                
                if not overbought_etfs and not oversold_etfs:
                    st.info("**å½“å‰çŠ¶æ€**ï¼šæ‰€æœ‰ETFéƒ½å¤„äºæ­£å¸¸åŒºé—´ï¼Œæ— æ˜æ˜¾è¶…ä¹°è¶…å–ä¿¡å·")
                
            else:
                st.warning("æ— æ³•è·å–BIASåˆ†ææ•°æ®")
                
        except Exception as e:
            st.error(f"BIASåˆ†æå¤±è´¥: {e}")
        
        # æ·»åŠ è¶‹åŠ¿åˆ†æè¯´æ˜
        st.info("""
        **è¶‹åŠ¿å›¾è¯´æ˜ï¼š**
        - æ¨ªåæ ‡ï¼šæ—¶é—´ï¼ˆè¿‘ä¸€å¹´ï¼‰
        - çºµåæ ‡ï¼šç´¯è®¡æ¶¨è·Œå¹…ï¼ˆä»¥å¹´åˆä¸ºåŸºå‡†ï¼‰
        - é›¶çº¿ï¼šç°è‰²è™šçº¿è¡¨ç¤ºæ— æ¶¨è·Œçš„åŸºå‡†çº¿
        - å½©è‰²å®çº¿ï¼šå„ETFçš„èµ°åŠ¿ï¼Œä¾¿äºå¯¹æ¯”åˆ†æ
        - ğŸ† ç­‰æƒé…ç½®ï¼šçº¢è‰²è™šçº¿è¡¨ç¤ºç­‰æƒé‡é…ç½®çš„æ”¶ç›Šè¡¨ç°
        - è¶‹åŠ¿å‘ä¸Šè¡¨ç¤ºèµ„äº§è¡¨ç°è‰¯å¥½ï¼Œè¶‹åŠ¿å‘ä¸‹è¡¨ç¤ºèµ„äº§è¡¨ç°ä¸ä½³
        """)
        
    else:
        st.warning("æš‚æ— ç¬¦åˆæ¡ä»¶çš„ETFï¼Œå»ºè®®ç©ºä»“")
    
    st.markdown("---")
    st.markdown("""
    **ç­–ç•¥è¯´æ˜ï¼š**
    - ä»…æŒæœ‰ä»·æ ¼é«˜äºå‡çº¿çš„èµ„äº§ï¼Œé¿å…ä¸‹è·Œè¶‹åŠ¿è¸©é›·
    - åŠ¨é‡å‘¨æœŸã€å‡çº¿å‘¨æœŸã€æœ€å¤§æŒä»“æ•°é‡å‡å¯è‡ªå®šä¹‰
    - æ¨èæŒä»“ä¸ºç­‰æƒåˆ†é…ï¼Œä¾¿äºå®ç›˜è·Ÿè¸ª
    - æœ¬å·¥å…·ä¸æ„æˆæŠ•èµ„å»ºè®®ï¼ŒæŠ•èµ„éœ€è°¨æ…
    """)

# æ·»åŠ æ‰‹åŠ¨åˆ·æ–°æŒ‰é’®
if st.button("ğŸ”„ æ‰‹åŠ¨åˆ·æ–°æ•°æ®"):
    # æ¸…é™¤ç¼“å­˜ç»“æœï¼Œå¼ºåˆ¶é‡æ–°è®¡ç®—
    if 'momentum_results' in st.session_state:
        del st.session_state.momentum_results
    if 'momentum_params' in st.session_state:
        del st.session_state.momentum_params
    st.rerun()